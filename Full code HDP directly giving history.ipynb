{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import cv2\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.segmentation import find_boundaries\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.linalg import inv\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reading(file_path):\n",
    "    #reading annotations file\n",
    "    ann_file = open(file_path,\"r\") #opening file in read mode only\n",
    "    strings = [x.strip() for x in ann_file.readlines()]\n",
    "    stimes=[]\n",
    "    etimes=[]\n",
    "    for i in range(len(strings)):\n",
    "        s1,s2=strings[i].split(\"-\")\n",
    "        stimes.append(s1.strip())\n",
    "        etimes.append(s2.strip())\n",
    "    return stimes,etimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(stime,etime,abnormal_stimes,abnormal_etimes):\n",
    "    length = len(abnormal_stimes)\n",
    "    for i in range(length):\n",
    "        t1 = datetime.strptime(abnormal_stimes[i], '%M:%S').time()\n",
    "        t2 = datetime.strptime(abnormal_etimes[i], '%M:%S').time()\n",
    "        obj1 = timedelta(hours=t1.hour, minutes=t1.minute, seconds=t1.second)\n",
    "        obj2 = timedelta(hours=t2.hour, minutes=t2.minute, seconds=t2.second)\n",
    "        if (stime >= obj1 and etime <= obj2) or (stime < obj1 and etime > obj1) or (stime < obj2 and etime > obj2):\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeling_objects:\n",
    "    def __init__(self,clip_no,stime,etime,label,interest_points,segments):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.label = label\n",
    "        self.interest_points = interest_points\n",
    "        self.segments = segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_superpixels(flow,segments,frame):\n",
    "    no_of_superpixels = segments.max()+1\n",
    "    #print(no_of_superpixels)\n",
    "    height,width = segments.shape\n",
    "    count = [0]*no_of_superpixels\n",
    "    points = []\n",
    "    threshold = [5.00000000e-05,5.00000000e-05]\n",
    "    #threshold = 2.00000000e-05\n",
    "    #mag = cv2.cartToPolar(flow[...,0],flow[...,1])[0]\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if abs(flow[i][j][0]) > threshold[0] or abs(flow[i][j][1]) > threshold[0]:\n",
    "            #if mag[i][j]>threshold:\n",
    "                points.append([i,j])\n",
    "    #new_frame = frame\n",
    "    points = np.asarray(points)\n",
    "    #print(\"points array shape\",points.shape)\n",
    "    \n",
    "    for index in range(len(points)):\n",
    "        seg = segments[points[index][0]][points[index][1]]\n",
    "        count[seg]+= 1\n",
    "        #new_frame = cv2.circle(new_frame,tuple(points[index]),2,(0,0,255), -1)\n",
    "\n",
    "    active_superpixels = [True]*no_of_superpixels\n",
    "    for i in range(no_of_superpixels):\n",
    "        total_count = np.count_nonzero(segments==i) #counting total no of pixels in superpixel i\n",
    "        #print(\"total no of pixels in superpixel\",i,\"is \",total_count)\n",
    "        #print(\"active pixels in superpixel\",i,\"is \",count[i])\n",
    "        if count[i] >= 0.4*total_count:\n",
    "            active_superpixels[i] = False\n",
    "\n",
    "    #print(\"Total no of superpixels \",no_of_superpixels)\n",
    "    #cv2.imshow('frame',new_frame)\n",
    "    #cv2.waitKey(3000)\n",
    "    #cv2.destroyAllWindows()\n",
    "    return active_superpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total frames  7824\n"
     ]
    }
   ],
   "source": [
    "video_path = 'E:\\\\Study\\\\Sem Project\\\\Data\\\\traffic-junction.avi'\n",
    "ann_file_path = \"E:\\\\Study\\\\Sem Project\\\\Data\\\\abnormal_times.txt\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 500,   # How many pts. to locate\n",
    "                       qualityLevel = 0.1,  # b/w 0 & 1, min. quality below which everyone is rejected\n",
    "                       minDistance = 7,   # Min eucledian distance b/w corners detected\n",
    "                       blockSize = 3 ) # Size of an average block for computing a derivative covariation matrix over each pixel neighborhood\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),  # size of the search window at each pyramid level\n",
    "                  maxLevel = 2,   #  0, pyramids are not used (single level), if set to 1, two levels are used, and so on\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "''' Criteria : Termination criteria for iterative search algorithm.\n",
    "    after maxcount { Criteria_Count } : no. of max iterations.\n",
    "    or after { Criteria Epsilon } : search window moves by less than this epsilon '''\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "clip = 0\n",
    "count = 0  # for the frame count\n",
    "n = 50  # Frames refresh rate for feature generation\n",
    "\n",
    "interest_points = []\n",
    "history_all_clips = [] # to track the history of frames.\n",
    "\n",
    "#for labeling the clips \n",
    "abnormal_stimes,abnormal_etimes = file_reading(ann_file_path)\n",
    "secs=0\n",
    "label_objects_array = []\n",
    "frames = []\n",
    "active_super_pixels_array = []\n",
    "seg_array = []\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    count+=1\n",
    "    \n",
    "    #cutting the clip, finding the interest points for last frame\n",
    "    if count%n == 0 or (len(frames)!=0 and (count == total_frames)):\n",
    "        if(len(frames)==50):\n",
    "            secs = secs+2\n",
    "            stime = timedelta(seconds = secs-2)\n",
    "            etime = timedelta(seconds = secs)\n",
    "            label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "        else:\n",
    "            secs = secs+1\n",
    "            stime = timedelta(seconds = secs-1)\n",
    "            etime = timedelta(seconds = secs)\n",
    "            label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "        \n",
    "        len_frame = len(frames)\n",
    "        old_frame = frames[len_frame-1]\n",
    "        # Convert to Grey Frame\n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        segments = slic(old_frame, n_segments = 144, sigma = 5,compactness = 25)\n",
    "        seg_array.append(segments)\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        #features for ending frame\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        t = np.ones(shape = (len(p0),1))\n",
    "        \n",
    "        label_objects_array.append(labeling_objects(clip,stime,etime,label,p0[t==1],segments.copy()))\n",
    "        clip += 1\n",
    "        \n",
    "        history_clip = defaultdict(list)\n",
    "        #if count%10 == 0: # Refresh the tracking features after every 10 frames\n",
    "        #    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        \n",
    "        for i in range(len(frames)-1,0,-1):\n",
    "            # calculate optical flow\n",
    "            frame_new = frames[i]\n",
    "            frame_gray = cv2.cvtColor(frame_new,cv2.COLOR_BGR2GRAY)\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "            if i==len(frames)-1:\n",
    "                flow = cv2.calcOpticalFlowFarneback(old_gray,frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                flow=np.asarray(flow)\n",
    "                active_super_pixels_array.append(active_superpixels(flow,segments,old_frame))\n",
    "            # Select good points\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "\n",
    "            # draw the tracks\n",
    "            for j,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                if i == len(frames)-1:\n",
    "                    history_clip[j].append(old)\n",
    "                    history_clip[j].append(new)\n",
    "                else:\n",
    "                    history_clip[j].append(new)\n",
    "                #a,b = new.ravel() #tmp new value\n",
    "                #c,d = old.ravel() #tmp old value\n",
    "                \n",
    "                #draws a line connecting the old point with the new point\n",
    "                #mask = cv2.line(mask, (a,b),(c,d), (0,0,255), 1)\n",
    "\n",
    "                #draws the new point\n",
    "                #frame = cv2.circle(frame,(a,b),2,(0,255,0), -1)\n",
    "            \"\"\"\n",
    "            img = cv2.add(frame,mask)\n",
    "            \n",
    "            cv2.imshow('frame',img)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "            #Show the Output\n",
    "            if k == 27:\n",
    "                cv2.imshow('', img)\n",
    "                break\n",
    "            \"\"\"\n",
    "            # Now update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1,1,2)\n",
    "        frames = []\n",
    "        history_all_clips.append(history_clip)\n",
    "\n",
    "print(\"total frames \",count)\n",
    "# release and destroy all windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"history length\",len(history_all_clips))\\nprint(\"label objects length\",len(label_objects_array))\\nprint(\"length of active super pixels array\",len(active_super_pixels_array))\\nfor i in range(len(active_super_pixels_array)):\\n    print(\"no of active superpixels in clip \",i,\"is\",np.count_nonzero(active_super_pixels_array[i]))\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"total clips\",clip)\n",
    "\"\"\"\n",
    "print(\"history length\",len(history_all_clips))\n",
    "print(\"label objects length\",len(label_objects_array))\n",
    "print(\"length of active super pixels array\",len(active_super_pixels_array))\n",
    "for i in range(len(active_super_pixels_array)):\n",
    "    print(\"no of active superpixels in clip \",i,\"is\",np.count_nonzero(active_super_pixels_array[i]))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_formation(image):\n",
    "    shape = image.shape\n",
    "    x_val = shape[0]//3\n",
    "    y_val = shape[1]//3\n",
    "    regions_arr = image.reshape(int(shape[0]/x_val), x_val, -1, y_val).swapaxes(1,2).reshape(-1, x_val, y_val)\n",
    "    return regions_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_length(val,arr):\n",
    "    small_index = 0\n",
    "    small_count = math.inf\n",
    "    for i in range(len(arr)):\n",
    "        if val in arr[i]:\n",
    "            if small_count > len(arr[i]):\n",
    "                small_count = len(arr[i])\n",
    "                small_index = i\n",
    "    return small_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_list(c, region_list):\n",
    "    for i in range(len(region_list)):\n",
    "        if c in region_list[i]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_and_superpixels(segments):\n",
    "    #dividing the entire frame into regions assigning each pixel location to region number\n",
    "    #output: regions_ar- contains the information of superpixels belongs to that region\n",
    "    #        region_segments - for a particular pixel location its associated region number.\n",
    "    regions = region_formation(segments)\n",
    "    region_index = defaultdict(set)\n",
    "    x,m,n = regions.shape\n",
    "    for i in range(x):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                region_index[i].add(regions[i][j][k])\n",
    "    regions_ar = defaultdict(list)\n",
    "    for i in range(len(region_index)):\n",
    "        regions_ar[i]=list(region_index[i])\n",
    "    for i in range(len(regions_ar)):\n",
    "        for j in range(len(regions_ar[i])):\n",
    "            region_num = small_length(regions_ar[i][j],regions)\n",
    "            for ind in range(len(regions_ar)):\n",
    "                if ind!=region_num and ind!=i:\n",
    "                    if regions_ar[i][j] in regions_ar[ind]:\n",
    "                        regions_ar[ind].remove(regions_ar[i][j])\n",
    "    # printing here region number and its particular superpixels. \n",
    "    #for i in range(len(regions_ar)):\n",
    "    #    print(\"region\",i,\" \",regions_ar[i])\n",
    "    region_segments = np.zeros_like(segments)\n",
    "    for i in range(len(segments)):\n",
    "        for j in range(len(segments[i])):\n",
    "            region_segments[i][j] = in_list(segments[i][j],regions_ar)\n",
    "    #for i in range(len(region_segments)):\n",
    "    #    print(region_segments[i])\n",
    "    return regions_ar,region_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_segments_array = []\n",
    "for i in range(len(label_objects_array)):\n",
    "    regions_ar,region_segments = region_and_superpixels(label_objects_array[i].segments)\n",
    "    region_segments_array.append(region_segments)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "49\n",
      "23\n"
     ]
    }
   ],
   "source": [
    "codebook_all_clips = []\n",
    "for i in range(len(history_all_clips)):\n",
    "    #print(i,\"th clip no of interest points\",len(history_all_clips[i]))\n",
    "    codebook_region = defaultdict(list)\n",
    "    for j in range(len(history_all_clips[i])):\n",
    "        history = history_all_clips[i][j]\n",
    "        flow_value =[]\n",
    "        #superpixel value \n",
    "        suppix = label_objects_array[i].segments[int(history[0][1])][int(history[0][0])]\n",
    "        region = region_segments_array[i][int(history[0][1])][int(history[0][0])]\n",
    "        for k in range(len(history)-1):\n",
    "            flow_value.append([history[k][0]-history[k+1][0],history[k][1]-history[k+1][1]])\n",
    "        flow_value = np.asarray(flow_value)\n",
    "        mag = cv2.cartToPolar(flow_value[:,0],flow_value[:,1])[0]\n",
    "        mag = mag.flatten()\n",
    "        codebook_region[region].append(np.asarray(mag))\n",
    "    region_array = np.asarray(list(codebook_region.values()))\n",
    "    #print(len(region_array[0][0]))\n",
    "    codebook_all_clips.append(region_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class DefaultDict(dict):\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "        dict.__init__(self)\n",
    "    def __getitem__(self, k):\n",
    "        return dict.__getitem__(self, k) if k in self else self.v\n",
    "    def update(self, d):\n",
    "        dict.update(self, d)\n",
    "        return self\n",
    "\n",
    "class HDPLDA:\n",
    "    def __init__(self, alpha, beta, gamma, docs, V):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.V = V\n",
    "        self.M = len(docs)\n",
    "\n",
    "        # t : table index for document j\n",
    "        #     t=0 means to draw a new table\n",
    "        self.using_t = [[0] for j in range(self.M)]\n",
    "\n",
    "        # k : dish(topic) index\n",
    "        #     k=0 means to draw a new dish\n",
    "        self.using_k = [0]\n",
    "\n",
    "        self.x_ji = docs # vocabulary for each document and term\n",
    "        self.k_jt = [numpy.zeros(1 ,dtype=int) for j in range(self.M)]   # topics of document and table\n",
    "        self.n_jt = [numpy.zeros(1 ,dtype=int) for j in range(self.M)]   # number of terms for each table of document\n",
    "        self.n_jtv = [[None] for j in range(self.M)]\n",
    "\n",
    "        self.m = 0\n",
    "        self.m_k = numpy.ones(1 ,dtype=int)  # number of tables for each topic\n",
    "        self.n_k = numpy.array([self.beta * self.V]) # number of terms for each topic ( + beta * V )\n",
    "        self.n_kv = [DefaultDict(0)]            # number of terms for each topic and vocabulary ( + beta )\n",
    "\n",
    "        # table for each document and term (-1 means not-assigned)\n",
    "        self.t_ji = [numpy.zeros(len(x_i), dtype=int) - 1 for x_i in docs]\n",
    "                    \n",
    "\n",
    "    def worddist(self):\n",
    "        \"\"\"return topic-word distribution without new topic\"\"\"\n",
    "        return [DefaultDict(self.beta / self.n_k[k]).update(\n",
    "            (v, n_kv / self.n_k[k]) for v, n_kv in self.n_kv[k].items())\n",
    "                for k in self.using_k if k != 0]\n",
    "\n",
    "    def docdist(self):\n",
    "        \"\"\"return document-topic distribution with new topic\"\"\"\n",
    "\n",
    "        # am_k = effect from table-dish assignment\n",
    "        am_k = numpy.array(self.m_k, dtype=float)\n",
    "        am_k[0] = self.gamma\n",
    "        am_k *= self.alpha / am_k[self.using_k].sum()\n",
    "\n",
    "        theta = []\n",
    "        for j, n_jt in enumerate(self.n_jt):\n",
    "            p_jk = am_k.copy()\n",
    "            for t in self.using_t[j]:\n",
    "                if t == 0: continue\n",
    "                k = self.k_jt[j][t]\n",
    "                p_jk[k] += n_jt[t]\n",
    "            p_jk = p_jk[self.using_k]\n",
    "            theta.append(p_jk / p_jk.sum())\n",
    "\n",
    "        return numpy.array(theta)\n",
    "    \n",
    "    def dump(self, disp_x=False):\n",
    "        if disp_x: print(\"x_ji:\", self.x_ji)\n",
    "        print(\"using_t:\", self.using_t)\n",
    "        print(\"t_ji:\", self.t_ji)\n",
    "        print(\"using_k:\", self.using_k)\n",
    "        print(\"k_jt:\", self.k_jt)\n",
    "        print(\"----\")\n",
    "        print(\"n_jt:\", self.n_jt)\n",
    "        print(\"n_jtv:\", self.n_jtv)\n",
    "        print(\"n_k:\", self.n_k)\n",
    "        print(\"n_kv:\", self.n_kv)\n",
    "        print(\"m:\", self.m)\n",
    "        print(\"m_k:\", self.m_k)\n",
    "\n",
    "\n",
    "    def sampling_t(self, j, i):\n",
    "        \"\"\"sampling t (table) from posterior\"\"\"\n",
    "        self.leave_from_table(j, i)\n",
    "\n",
    "        v = self.x_ji[j][i]\n",
    "        f_k = self.calc_f_k(v)\n",
    "        assert f_k[0] == 0 # f_k[0] is a dummy and will be erased\n",
    "\n",
    "        # sampling from posterior p(t_ji=t)\n",
    "        p_t = self.calc_table_posterior(j, f_k)\n",
    "        if len(p_t) > 1 and p_t[1] < 0: self.dump()\n",
    "        t_new = self.using_t[j][numpy.random.multinomial(1, p_t).argmax()]\n",
    "        if t_new == 0:\n",
    "            p_k = self.calc_dish_posterior_w(f_k)\n",
    "            k_new = self.using_k[numpy.random.multinomial(1, p_k).argmax()]\n",
    "            if k_new == 0:\n",
    "                k_new = self.add_new_dish()\n",
    "            t_new = self.add_new_table(j, k_new)\n",
    "\n",
    "        # increase counters\n",
    "        self.seat_at_table(j, i, t_new)\n",
    "        return p_t\n",
    "\n",
    "    def leave_from_table(self, j, i):\n",
    "        t = self.t_ji[j][i]\n",
    "        if t  > 0:\n",
    "            k = self.k_jt[j][t]\n",
    "            assert k > 0\n",
    "\n",
    "            # decrease counters\n",
    "            v = self.x_ji[j][i]\n",
    "            self.n_kv[k][v] -= 1\n",
    "            self.n_k[k] -= 1\n",
    "            self.n_jt[j][t] -= 1\n",
    "            self.n_jtv[j][t][v] -= 1\n",
    "\n",
    "            if self.n_jt[j][t] == 0:\n",
    "                self.remove_table(j, t)\n",
    "\n",
    "    def remove_table(self, j, t):\n",
    "        \"\"\"remove the table where all guests are gone\"\"\"\n",
    "        k = self.k_jt[j][t]\n",
    "        self.using_t[j].remove(t)\n",
    "        self.m_k[k] -= 1\n",
    "        self.m -= 1\n",
    "        assert self.m_k[k] >= 0\n",
    "        if self.m_k[k] == 0:\n",
    "            # remove topic (dish) where all tables are gone\n",
    "            self.using_k.remove(k)\n",
    "\n",
    "    def calc_f_k(self, v):\n",
    "        return [n_kv[v] for n_kv in self.n_kv] / self.n_k\n",
    "\n",
    "    def calc_table_posterior(self, j, f_k):\n",
    "        using_t = self.using_t[j]\n",
    "        p_t = self.n_jt[j][using_t] * f_k[self.k_jt[j][using_t]]\n",
    "        p_x_ji = numpy.inner(self.m_k, f_k) + self.gamma / self.V\n",
    "        p_t[0] = p_x_ji * self.alpha / (self.gamma + self.m)\n",
    "        #print(\"un-normalized p_t = \", p_t)\n",
    "        return p_t / p_t.sum()\n",
    "\n",
    "    def seat_at_table(self, j, i, t_new):\n",
    "        assert t_new in self.using_t[j]\n",
    "        self.t_ji[j][i] = t_new\n",
    "        self.n_jt[j][t_new] += 1\n",
    "\n",
    "        k_new = self.k_jt[j][t_new]\n",
    "        self.n_k[k_new] += 1\n",
    "\n",
    "        v = self.x_ji[j][i]\n",
    "        self.n_kv[k_new][v] += 1\n",
    "        self.n_jtv[j][t_new][v] += 1\n",
    "\n",
    "    # Assign guest x_ji to a new table and draw topic (dish) of the table\n",
    "    def add_new_table(self, j, k_new):\n",
    "        assert k_new in self.using_k\n",
    "        for t_new, t in enumerate(self.using_t[j]):\n",
    "            if t_new != t: break\n",
    "        else:\n",
    "            t_new = len(self.using_t[j])\n",
    "            self.n_jt[j].resize(t_new+1)\n",
    "            self.k_jt[j].resize(t_new+1)\n",
    "            self.n_jtv[j].append(None)\n",
    "\n",
    "        self.using_t[j].insert(t_new, t_new)\n",
    "        self.n_jt[j][t_new] = 0  # to make sure\n",
    "        self.n_jtv[j][t_new] = DefaultDict(0)\n",
    "\n",
    "        self.k_jt[j][t_new] = k_new\n",
    "        self.m_k[k_new] += 1\n",
    "        self.m += 1\n",
    "\n",
    "        return t_new\n",
    "\n",
    "    def calc_dish_posterior_w(self, f_k):\n",
    "        \"calculate dish(topic) posterior when one word is removed\"\n",
    "        p_k = (self.m_k * f_k)[self.using_k]\n",
    "        p_k[0] = self.gamma / self.V\n",
    "        return p_k / p_k.sum()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling_k(self, j, t):\n",
    "        \"\"\"sampling k (dish=topic) from posterior\"\"\"\n",
    "        self.leave_from_dish(j, t)\n",
    "\n",
    "        # sampling of k\n",
    "        p_k = self.calc_dish_posterior_t(j, t)\n",
    "        k_new = self.using_k[numpy.random.multinomial(1, p_k).argmax()]\n",
    "        if k_new == 0:\n",
    "            k_new = self.add_new_dish()\n",
    "\n",
    "        self.seat_at_dish(j, t, k_new)\n",
    "\n",
    "    def leave_from_dish(self, j, t):\n",
    "        \"\"\"\n",
    "        This makes the table leave from its dish and only the table counter decrease.\n",
    "        The word counters (n_k and n_kv) stay.\n",
    "        \"\"\"\n",
    "        k = self.k_jt[j][t]\n",
    "        assert k > 0\n",
    "        assert self.m_k[k] > 0\n",
    "        self.m_k[k] -= 1\n",
    "        self.m -= 1\n",
    "        if self.m_k[k] == 0:\n",
    "            self.using_k.remove(k)\n",
    "            self.k_jt[j][t] = 0\n",
    "\n",
    "    def calc_dish_posterior_t(self, j, t):\n",
    "        \"calculate dish(topic) posterior when one table is removed\"\n",
    "        k_old = self.k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "        #print(\"V=\", self.V, \"beta=\", self.beta, \"n_k=\", self.n_k)\n",
    "        Vbeta = self.V * self.beta\n",
    "        n_k = self.n_k.copy()\n",
    "        n_jt = self.n_jt[j][t]\n",
    "        n_k[k_old] -= n_jt\n",
    "        n_k = n_k[self.using_k]\n",
    "        log_p_k = numpy.log(self.m_k[self.using_k]) + gammaln(n_k) - gammaln(n_k + n_jt)\n",
    "        log_p_k_new = numpy.log(self.gamma) + gammaln(Vbeta) - gammaln(Vbeta + n_jt)\n",
    "        #print(\"log_p_k_new+=gammaln(\",Vbeta,\") - gammaln(\",Vbeta + n_jt,\")\")\n",
    "\n",
    "        gammaln_beta = gammaln(self.beta)\n",
    "        for w, n_jtw in self.n_jtv[j][t].items():\n",
    "            assert n_jtw >= 0\n",
    "            if n_jtw == 0: continue\n",
    "            n_kw = numpy.array([n.get(w, self.beta) for n in self.n_kv])\n",
    "            n_kw[k_old] -= n_jtw\n",
    "            n_kw = n_kw[self.using_k]\n",
    "            n_kw[0] = 1 # dummy for logarithm's warning\n",
    "            if numpy.any(n_kw <= 0): print(n_kw) # for debug\n",
    "            log_p_k += gammaln(n_kw + n_jtw) - gammaln(n_kw)\n",
    "            log_p_k_new += gammaln(self.beta + n_jtw) - gammaln_beta\n",
    "            #print(\"log_p_k_new+=gammaln(\",self.beta + n_jtw,\") - gammaln(\",self.beta,\"), w=\",w)\n",
    "        log_p_k[0] = log_p_k_new\n",
    "        #print(\"un-normalized p_k = \", numpy.exp(log_p_k))\n",
    "        p_k = numpy.exp(log_p_k - log_p_k.max())\n",
    "        return p_k / p_k.sum()\n",
    "\n",
    "    def seat_at_dish(self, j, t, k_new):\n",
    "        self.m += 1\n",
    "        self.m_k[k_new] += 1\n",
    "\n",
    "        k_old = self.k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "        if k_new != k_old:\n",
    "            self.k_jt[j][t] = k_new\n",
    "\n",
    "            n_jt = self.n_jt[j][t]\n",
    "            if k_old != 0: self.n_k[k_old] -= n_jt\n",
    "            self.n_k[k_new] += n_jt\n",
    "            for v, n in self.n_jtv[j][t].items():\n",
    "                if k_old != 0: self.n_kv[k_old][v] -= n\n",
    "                self.n_kv[k_new][v] += n\n",
    "\n",
    "\n",
    "    def add_new_dish(self):\n",
    "        \"This is commonly used by sampling_t and sampling_k.\"\n",
    "        for k_new, k in enumerate(self.using_k):\n",
    "            if k_new != k: break\n",
    "        else:\n",
    "            k_new = len(self.using_k)\n",
    "            if k_new >= len(self.n_kv):\n",
    "                self.n_k = numpy.resize(self.n_k, k_new + 1)\n",
    "                self.m_k = numpy.resize(self.m_k, k_new + 1)\n",
    "                self.n_kv.append(None)\n",
    "            assert k_new == self.using_k[-1] + 1\n",
    "            assert k_new < len(self.n_kv)\n",
    "\n",
    "        self.using_k.insert(k_new, k_new)\n",
    "        self.n_k[k_new] = self.beta * self.V\n",
    "        self.m_k[k_new] = 0\n",
    "        self.n_kv[k_new] = DefaultDict(self.beta)\n",
    "        return k_new\n",
    "    \n",
    "    def inference(self):\n",
    "        weights = []\n",
    "        for j, x_i in enumerate(self.x_ji):\n",
    "            p_t = []\n",
    "            for i in range(len(x_i)):\n",
    "                p_t = self.sampling_t(j, i)\n",
    "            weights.extend(p_t)\n",
    "        for j in range(self.M):\n",
    "            for t in self.using_t[j]:\n",
    "                if t != 0: self.sampling_k(j, t)\n",
    "        return np.asarray(weights).flatten()\n",
    "    \n",
    "    def hdplda_learning(self,iteration):\n",
    "        for i in range(iteration):\n",
    "            weights = self.inference()\n",
    "        return weights       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_objects:\n",
    "    def __init__(self,clip_no,stime,etime,weights_data,label):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.weights_data = weights_data\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip no  0\n",
      "weights 802\n",
      "clip no  1\n",
      "weights 784\n",
      "clip no  2\n",
      "weights 751\n",
      "clip no  3\n",
      "weights 812\n",
      "clip no  4\n",
      "weights 828\n",
      "clip no  5\n",
      "weights 835\n",
      "clip no  6\n",
      "weights 828\n",
      "clip no  7\n",
      "weights 901\n",
      "clip no  8\n",
      "weights 888\n",
      "clip no  9\n",
      "weights 879\n",
      "clip no  10\n",
      "weights 888\n",
      "clip no  11\n",
      "weights 810\n",
      "clip no  12\n",
      "weights 861\n",
      "clip no  13\n",
      "weights 882\n",
      "clip no  14\n",
      "weights 966\n",
      "clip no  15\n",
      "weights 860\n",
      "clip no  16\n",
      "weights 841\n",
      "clip no  17\n",
      "weights 857\n",
      "clip no  18\n",
      "weights 723\n",
      "clip no  19\n",
      "weights 896\n",
      "clip no  20\n",
      "weights 837\n",
      "clip no  21\n",
      "weights 929\n",
      "clip no  22\n",
      "weights 907\n",
      "clip no  23\n",
      "weights 811\n",
      "clip no  24\n",
      "weights 918\n",
      "clip no  25\n",
      "weights 896\n",
      "clip no  26\n",
      "weights 853\n",
      "clip no  27\n",
      "weights 922\n",
      "clip no  28\n",
      "weights 883\n",
      "clip no  29\n",
      "weights 922\n",
      "clip no  30\n",
      "weights 796\n",
      "clip no  31\n",
      "weights 875\n",
      "clip no  32\n",
      "weights 914\n",
      "clip no  33\n",
      "weights 870\n",
      "clip no  34\n",
      "weights 1009\n",
      "clip no  35\n",
      "weights 929\n",
      "clip no  36\n",
      "weights 940\n",
      "clip no  37\n",
      "weights 983\n",
      "clip no  38\n",
      "weights 1006\n",
      "clip no  39\n",
      "weights 987\n",
      "clip no  40\n",
      "weights 917\n",
      "clip no  41\n",
      "weights 821\n",
      "clip no  42\n",
      "weights 1066\n",
      "clip no  43\n",
      "weights 890\n",
      "clip no  44\n",
      "weights 949\n",
      "clip no  45\n",
      "weights 955\n",
      "clip no  46\n",
      "weights 973\n",
      "clip no  47\n",
      "weights 901\n",
      "clip no  48\n",
      "weights 878\n",
      "clip no  49\n",
      "weights 864\n",
      "clip no  50\n",
      "weights 1007\n",
      "clip no  51\n",
      "weights 1076\n",
      "clip no  52\n",
      "weights 991\n",
      "clip no  53\n",
      "weights 1000\n",
      "clip no  54\n",
      "weights 843\n",
      "clip no  55\n",
      "weights 970\n",
      "clip no  56\n",
      "weights 857\n",
      "clip no  57\n",
      "weights 856\n",
      "clip no  58\n",
      "weights 873\n",
      "clip no  59\n",
      "weights 947\n",
      "clip no  60\n",
      "weights 857\n",
      "clip no  61\n",
      "weights 977\n",
      "clip no  62\n",
      "weights 915\n",
      "clip no  63\n",
      "weights 845\n",
      "clip no  64\n",
      "weights 806\n",
      "clip no  65\n",
      "weights 866\n",
      "clip no  66\n",
      "weights 862\n",
      "clip no  67\n",
      "weights 876\n",
      "clip no  68\n",
      "weights 941\n",
      "clip no  69\n",
      "weights 930\n",
      "clip no  70\n",
      "weights 885\n",
      "clip no  71\n",
      "weights 913\n",
      "clip no  72\n",
      "weights 869\n",
      "clip no  73\n",
      "weights 973\n",
      "clip no  74\n",
      "weights 916\n",
      "clip no  75\n",
      "weights 851\n",
      "clip no  76\n",
      "weights 920\n",
      "clip no  77\n",
      "weights 933\n",
      "clip no  78\n",
      "weights 906\n",
      "clip no  79\n",
      "weights 947\n",
      "clip no  80\n",
      "weights 884\n",
      "clip no  81\n",
      "weights 938\n",
      "clip no  82\n",
      "weights 1001\n",
      "clip no  83\n",
      "weights 918\n",
      "clip no  84\n",
      "weights 759\n",
      "clip no  85\n",
      "weights 930\n",
      "clip no  86\n",
      "weights 864\n",
      "clip no  87\n",
      "weights 809\n",
      "clip no  88\n",
      "weights 864\n",
      "clip no  89\n",
      "weights 893\n",
      "clip no  90\n",
      "weights 874\n",
      "clip no  91\n",
      "weights 991\n",
      "clip no  92\n",
      "weights 966\n",
      "clip no  93\n",
      "weights 900\n",
      "clip no  94\n",
      "weights 934\n",
      "clip no  95\n",
      "weights 900\n",
      "clip no  96\n",
      "weights 838\n",
      "clip no  97\n",
      "weights 864\n",
      "clip no  98\n",
      "weights 1050\n",
      "clip no  99\n",
      "weights 885\n",
      "clip no  100\n",
      "weights 892\n",
      "clip no  101\n",
      "weights 876\n",
      "clip no  102\n",
      "weights 893\n",
      "clip no  103\n",
      "weights 869\n",
      "clip no  104\n",
      "weights 948\n",
      "clip no  105\n",
      "weights 951\n",
      "clip no  106\n",
      "weights 897\n",
      "clip no  107\n",
      "weights 872\n",
      "clip no  108\n",
      "weights 917\n",
      "clip no  109\n",
      "weights 841\n",
      "clip no  110\n",
      "weights 948\n",
      "clip no  111\n",
      "weights 941\n",
      "clip no  112\n",
      "weights 1026\n",
      "clip no  113\n",
      "weights 921\n",
      "clip no  114\n",
      "weights 789\n",
      "clip no  115\n",
      "weights 926\n",
      "clip no  116\n",
      "weights 940\n",
      "clip no  117\n",
      "weights 949\n",
      "clip no  118\n",
      "weights 726\n",
      "clip no  119\n",
      "weights 883\n",
      "clip no  120\n",
      "weights 745\n",
      "clip no  121\n",
      "weights 667\n",
      "clip no  122\n",
      "weights 737\n",
      "clip no  123\n",
      "weights 768\n",
      "clip no  124\n",
      "weights 812\n",
      "clip no  125\n",
      "weights 842\n",
      "clip no  126\n",
      "weights 853\n",
      "clip no  127\n",
      "weights 936\n",
      "clip no  128\n",
      "weights 893\n",
      "clip no  129\n",
      "weights 821\n",
      "clip no  130\n",
      "weights 807\n",
      "clip no  131\n",
      "weights 863\n",
      "clip no  132\n",
      "weights 808\n",
      "clip no  133\n",
      "weights 921\n",
      "clip no  134\n",
      "weights 781\n",
      "clip no  135\n",
      "weights 965\n",
      "clip no  136\n",
      "weights 805\n",
      "clip no  137\n",
      "weights 1055\n",
      "clip no  138\n",
      "weights 764\n",
      "clip no  139\n",
      "weights 946\n",
      "clip no  140\n",
      "weights 756\n",
      "clip no  141\n",
      "weights 808\n",
      "clip no  142\n",
      "weights 867\n",
      "clip no  143\n",
      "weights 872\n",
      "clip no  144\n",
      "weights 861\n",
      "clip no  145\n",
      "weights 837\n",
      "clip no  146\n",
      "weights 844\n",
      "clip no  147\n",
      "weights 902\n",
      "clip no  148\n",
      "weights 830\n",
      "clip no  149\n",
      "weights 949\n",
      "clip no  150\n",
      "weights 967\n",
      "clip no  151\n",
      "weights 828\n",
      "clip no  152\n",
      "weights 861\n",
      "clip no  153\n",
      "weights 884\n",
      "clip no  154\n",
      "weights 792\n",
      "clip no  155\n",
      "weights 710\n",
      "clip no  156\n",
      "weights 605\n"
     ]
    }
   ],
   "source": [
    "data_object_array=[]\n",
    "loa = label_objects_array\n",
    "for i in range(len(codebook_all_clips)):\n",
    "    print(\"clip no \",i)\n",
    "    clip_weights = []\n",
    "    for j in range(len(codebook_all_clips[i])):\n",
    "        #print(\"region no\",j)\n",
    "        if len(codebook_all_clips[i][j])!=0:\n",
    "            hdplda = HDPLDA(1,1,1, codebook_all_clips[i][j],(12*12)+1)\n",
    "            weights = hdplda.hdplda_learning(3)\n",
    "            clip_weights.extend(weights)\n",
    "    data_object_array.append(data_objects(loa[i].clip_no,loa[i].stime,loa[i].etime,np.asarray(clip_weights).flatten(),loa[i].label)) \n",
    "    print(\"weights\",len(clip_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"total no of objects\",len(total_data_objects))\\nfor i in range(len(total_data_objects)):\\n    print(\"clip no=\",total_data_objects[i].clip_no)\\n    print(\"start time=\",total_data_objects[i].stime)\\n    print(\"end time=\",total_data_objects[i].etime)\\n    print(\"weights =\",total_data_objects[i].weights_data)\\n    print(\"label = \",total_data_objects[i].label,\"\\n\")\\n    '"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data_objects = data_object_array\n",
    "\"\"\"\n",
    "print(\"total no of objects\",len(total_data_objects))\n",
    "for i in range(len(total_data_objects)):\n",
    "    print(\"clip no=\",total_data_objects[i].clip_no)\n",
    "    print(\"start time=\",total_data_objects[i].stime)\n",
    "    print(\"end time=\",total_data_objects[i].etime)\n",
    "    print(\"weights =\",total_data_objects[i].weights_data)\n",
    "    print(\"label = \",total_data_objects[i].label,\"\\n\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing weights.\n",
    "for i in range(len(total_data_objects)):\n",
    "    sum = np.sum(total_data_objects[i].weights_data)\n",
    "    for j in range(len(total_data_objects[i].weights_data)):\n",
    "        total_data_objects[i].weights_data[j] = total_data_objects[i].weights_data[j] / sum\n",
    "    total_data_objects[i].weights_data = np.asarray(total_data_objects[i].weights_data)\n",
    "    #print(\"sum \",i,\"\",np.sum(total_data_objects[i].weights_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 1076\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(total_data_objects)):\\n    for j in range(len(total_data_objects[i].weights_data)-min_len):\\n        total_data_objects[i].weights_data = np.delete(total_data_objects[i].weights_data,j)\\n\\nprint(\"after preprocessing lengths\")\\nfor i in range(len(total_data_objects)):\\n    print(len(total_data_objects[i].weights_data))\\n'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(total_data_objects[0].weights_data)\n",
    "for i in range(len(total_data_objects)):\n",
    "    if max_len < len(total_data_objects[i].weights_data):\n",
    "        max_len = len(total_data_objects[i].weights_data)\n",
    "print(\"max len\",max_len)\n",
    "\n",
    "\"\"\"\n",
    "min_len = len(total_data_objects[0].weights_data)\n",
    "for i in range(len(total_data_objects)):\n",
    "    if min_len > len(total_data_objects[i].weights_data):\n",
    "        min_len = len(total_data_objects[i].weights_data)\n",
    "print(\"min len\",min_len)\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(total_data_objects)):\n",
    "    for j in range(max_len - len(total_data_objects[i].weights_data)):\n",
    "        total_data_objects[i].weights_data = np.append(total_data_objects[i].weights_data,0)\n",
    "\n",
    "for i in range(len(total_data_objects)):\n",
    "    #print(\"clip no\",i)\n",
    "    for j in range(len(total_data_objects[i].weights_data)):\n",
    "        if total_data_objects[i].weights_data[j] == 0:\n",
    "            total_data_objects[i].weights_data[j] = np.mean([total_data_objects[ind].weights_data[j] for ind in range(len(total_data_objects))])\n",
    "\"\"\"\n",
    "for i in range(len(total_data_objects)):\n",
    "    for j in range(len(total_data_objects[i].weights_data)-min_len):\n",
    "        total_data_objects[i].weights_data = np.delete(total_data_objects[i].weights_data,j)\n",
    "\n",
    "print(\"after preprocessing lengths\")\n",
    "for i in range(len(total_data_objects)):\n",
    "    print(len(total_data_objects[i].weights_data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total objects= 157\n",
      "train objects= 94\n",
      "test objects= 63\n"
     ]
    }
   ],
   "source": [
    "#dividing the total dataset into 60% training and 40% test\n",
    "total_no = len(total_data_objects)\n",
    "print(\"total objects=\",total_no)\n",
    "train_no=round(0.6*total_no)\n",
    "print(\"train objects=\",train_no)\n",
    "test_no=round(0.4*total_no)\n",
    "print(\"test objects=\",test_no)\n",
    "\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_train=[]\n",
    "Y_test=[]\n",
    "\n",
    "np.random.shuffle(total_data_objects)\n",
    "for i in range(train_no):\n",
    "    X_train.append(np.asarray(total_data_objects[i].weights_data))\n",
    "    Y_train.append(total_data_objects[i].label)\n",
    "for i in range(train_no,total_no):\n",
    "    X_test.append(total_data_objects[i].weights_data)\n",
    "    Y_test.append(total_data_objects[i].label)\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "X_train=np.asarray(X_train)\n",
    "#print(\"X_test\",X_test)\n",
    "#print(\"x_trin shape\",X_train.shape)\n",
    "#print(\"X_train\",X_train[0].shape)    \n",
    "\n",
    "Y_test=np.asarray(Y_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=Y_test\n",
    "Y_train=Y_train\n",
    "Y_test=Y_test.reshape(-1,1)\n",
    "Y_train=Y_train.reshape(-1,1)\n",
    "#print(len(Y_train))\n",
    "#print(Y_train[1:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (94, 1076)\n",
      "shape  (94, 1)\n",
      "labels predicted 63\n",
      "[[-1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1\n",
      "  -1 -1 -1 -1 -1  1 -1 -1  1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1  1 -1\n",
      "  -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1]]\n",
      "[-1  1 -1 -1 -1  1 -1 -1  1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1 -1 -1 -1 -1 -1 -1 -1 -1  1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape \",X_train.shape)\n",
    "print(\"shape \",Y_train.shape)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,Y_train)\n",
    "pred_labels=gnb.predict(X_test)\n",
    "print(\"labels predicted\",len(pred_labels))\n",
    "print(Y_test.reshape(1,-1))\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 79.36507936507937\n"
     ]
    }
   ],
   "source": [
    "#performance\n",
    "print(\"accuracy =\",accuracy_score(pred_labels,Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49  8]\n",
      " [ 5  1]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(pred_labels,Y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.51\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc = roc_auc_score(Y_test,pred_labels)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test,pred_labels)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
