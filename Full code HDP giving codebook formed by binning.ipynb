{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import csv\n",
    "import math\n",
    "import cv2\n",
    "import pickle\n",
    "from collections import defaultdict\n",
    "from datetime import datetime, timedelta\n",
    "from skimage.segmentation import slic\n",
    "from skimage.segmentation import mark_boundaries\n",
    "from skimage.segmentation import find_boundaries\n",
    "from collections import Counter\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from numpy.linalg import inv\n",
    "from sklearn.gaussian_process.kernels import RBF\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.gaussian_process import GaussianProcessClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def file_reading(file_path):\n",
    "    #reading annotations file\n",
    "    ann_file = open(file_path,\"r\") #opening file in read mode only\n",
    "    strings = [x.strip() for x in ann_file.readlines()]\n",
    "    stimes=[]\n",
    "    etimes=[]\n",
    "    for i in range(len(strings)):\n",
    "        s1,s2=strings[i].split(\"-\")\n",
    "        stimes.append(s1.strip())\n",
    "        etimes.append(s2.strip())\n",
    "    return stimes,etimes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(stime,etime,abnormal_stimes,abnormal_etimes):\n",
    "    length = len(abnormal_stimes)\n",
    "    for i in range(length):\n",
    "        t1 = datetime.strptime(abnormal_stimes[i], '%M:%S').time()\n",
    "        t2 = datetime.strptime(abnormal_etimes[i], '%M:%S').time()\n",
    "        obj1 = timedelta(hours=t1.hour, minutes=t1.minute, seconds=t1.second)\n",
    "        obj2 = timedelta(hours=t2.hour, minutes=t2.minute, seconds=t2.second)\n",
    "        if (stime >= obj1 and etime <= obj2) or (stime < obj1 and etime > obj1) or (stime < obj2 and etime > obj2):\n",
    "            return 1\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class labeling_objects:\n",
    "    def __init__(self,clip_no,stime,etime,label,interest_points,segments):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.label = label\n",
    "        self.interest_points = interest_points\n",
    "        self.segments = segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def active_superpixels(flow,segments,frame):\n",
    "    no_of_superpixels = segments.max()+1\n",
    "    #print(no_of_superpixels)\n",
    "    height,width = segments.shape\n",
    "    count = [0]*no_of_superpixels\n",
    "    points = []\n",
    "    threshold = [5.00000000e-05,5.00000000e-05]\n",
    "    #threshold = 2.00000000e-05\n",
    "    #mag = cv2.cartToPolar(flow[...,0],flow[...,1])[0]\n",
    "    \n",
    "    for i in range(height):\n",
    "        for j in range(width):\n",
    "            if abs(flow[i][j][0]) > threshold[0] or abs(flow[i][j][1]) > threshold[0]:\n",
    "            #if mag[i][j]>threshold:\n",
    "                points.append([i,j])\n",
    "    #new_frame = frame\n",
    "    points = np.asarray(points)\n",
    "    #print(\"points array shape\",points.shape)\n",
    "    \n",
    "    for index in range(len(points)):\n",
    "        seg = segments[points[index][0]][points[index][1]]\n",
    "        count[seg]+= 1\n",
    "        #new_frame = cv2.circle(new_frame,tuple(points[index]),2,(0,0,255), -1)\n",
    "\n",
    "    active_superpixels = [True]*no_of_superpixels\n",
    "    for i in range(no_of_superpixels):\n",
    "        total_count = np.count_nonzero(segments==i) #counting total no of pixels in superpixel i\n",
    "        #print(\"total no of pixels in superpixel\",i,\"is \",total_count)\n",
    "        #print(\"active pixels in superpixel\",i,\"is \",count[i])\n",
    "        if count[i] >= 0.4*total_count:\n",
    "            active_superpixels[i] = False\n",
    "\n",
    "    #print(\"Total no of superpixels \",no_of_superpixels)\n",
    "    #cv2.imshow('frame',new_frame)\n",
    "    #cv2.waitKey(3000)\n",
    "    #cv2.destroyAllWindows()\n",
    "    return active_superpixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total frames  7824\n"
     ]
    }
   ],
   "source": [
    "video_path = 'E:\\\\Study\\\\Sem Project\\\\Data\\\\traffic-junction.avi'\n",
    "ann_file_path = \"E:\\\\Study\\\\Sem Project\\\\Data\\\\abnormal_times.txt\"\n",
    "cap = cv2.VideoCapture(video_path)\n",
    "\n",
    "# params for ShiTomasi corner detection\n",
    "feature_params = dict( maxCorners = 500,   # How many pts. to locate\n",
    "                       qualityLevel = 0.1,  # b/w 0 & 1, min. quality below which everyone is rejected\n",
    "                       minDistance = 7,   # Min eucledian distance b/w corners detected\n",
    "                       blockSize = 3 ) # Size of an average block for computing a derivative covariation matrix over each pixel neighborhood\n",
    "\n",
    "# Parameters for lucas kanade optical flow\n",
    "lk_params = dict( winSize  = (15,15),  # size of the search window at each pyramid level\n",
    "                  maxLevel = 2,   #  0, pyramids are not used (single level), if set to 1, two levels are used, and so on\n",
    "                  criteria = (cv2.TERM_CRITERIA_EPS | cv2.TERM_CRITERIA_COUNT, 10, 0.03))\n",
    "\n",
    "''' Criteria : Termination criteria for iterative search algorithm.\n",
    "    after maxcount { Criteria_Count } : no. of max iterations.\n",
    "    or after { Criteria Epsilon } : search window moves by less than this epsilon '''\n",
    "\n",
    "total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "\n",
    "clip = 0\n",
    "count = 0  # for the frame count\n",
    "n = 50  # Frames refresh rate for feature generation\n",
    "\n",
    "interest_points = []\n",
    "history_all_clips = [] # to track the history of frames.\n",
    "\n",
    "#for labeling the clips \n",
    "abnormal_stimes,abnormal_etimes = file_reading(ann_file_path)\n",
    "secs=0\n",
    "label_objects_array = []\n",
    "frames = []\n",
    "active_super_pixels_array = []\n",
    "seg_array = []\n",
    "\n",
    "while True:\n",
    "    ret,frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    frames.append(frame)\n",
    "    count+=1\n",
    "    \n",
    "    #cutting the clip, finding the interest points for last frame\n",
    "    if count%n == 0 or (len(frames)!=0 and (count == total_frames)):\n",
    "        if(len(frames)==50):\n",
    "            secs = secs+2\n",
    "            stime = timedelta(seconds = secs-2)\n",
    "            etime = timedelta(seconds = secs)\n",
    "            label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "        else:\n",
    "            secs = secs+1\n",
    "            stime = timedelta(seconds = secs-1)\n",
    "            etime = timedelta(seconds = secs)\n",
    "            label = compare(stime,etime,abnormal_stimes,abnormal_etimes)\n",
    "        \n",
    "        len_frame = len(frames)\n",
    "        old_frame = frames[len_frame-1]\n",
    "        # Convert to Grey Frame\n",
    "        old_gray = cv2.cvtColor(old_frame, cv2.COLOR_BGR2GRAY)\n",
    "        segments = slic(old_frame, n_segments = 144, sigma = 5,compactness = 25)\n",
    "        seg_array.append(segments)\n",
    "        mask = np.zeros_like(old_frame)\n",
    "        \n",
    "        #features for ending frame\n",
    "        p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        t = np.ones(shape = (len(p0),1))\n",
    "        \n",
    "        label_objects_array.append(labeling_objects(clip,stime,etime,label,p0[t==1],segments.copy()))\n",
    "        clip += 1\n",
    "        \n",
    "        history_clip = defaultdict(list)\n",
    "        #if count%10 == 0: # Refresh the tracking features after every 10 frames\n",
    "        #    p0 = cv2.goodFeaturesToTrack(old_gray, mask=None, **feature_params)\n",
    "        \n",
    "        for i in range(len(frames)-1,0,-1):\n",
    "            # calculate optical flow\n",
    "            frame_new = frames[i]\n",
    "            frame_gray = cv2.cvtColor(frame_new,cv2.COLOR_BGR2GRAY)\n",
    "            p1, st, err = cv2.calcOpticalFlowPyrLK(old_gray, frame_gray, p0, None, **lk_params)\n",
    "            if i==len(frames)-1:\n",
    "                flow = cv2.calcOpticalFlowFarneback(old_gray,frame_gray, None, 0.5, 3, 15, 3, 5, 1.2, 0)\n",
    "                flow=np.asarray(flow)\n",
    "                active_super_pixels_array.append(active_superpixels(flow,segments,old_frame))\n",
    "            # Select good points\n",
    "            good_new = p1[st==1]\n",
    "            good_old = p0[st==1]\n",
    "\n",
    "            # draw the tracks\n",
    "            for j,(new,old) in enumerate(zip(good_new,good_old)):\n",
    "                if i == len(frames)-1:\n",
    "                    history_clip[j].append(old)\n",
    "                    history_clip[j].append(new)\n",
    "                else:\n",
    "                    history_clip[j].append(new)\n",
    "                #a,b = new.ravel() #tmp new value\n",
    "                #c,d = old.ravel() #tmp old value\n",
    "                \n",
    "                #draws a line connecting the old point with the new point\n",
    "                #mask = cv2.line(mask, (a,b),(c,d), (0,0,255), 1)\n",
    "\n",
    "                #draws the new point\n",
    "                #frame = cv2.circle(frame,(a,b),2,(0,255,0), -1)\n",
    "            \"\"\"\n",
    "            img = cv2.add(frame,mask)\n",
    "            \n",
    "            cv2.imshow('frame',img)\n",
    "            k = cv2.waitKey(30) & 0xff\n",
    "\n",
    "            #Show the Output\n",
    "            if k == 27:\n",
    "                cv2.imshow('', img)\n",
    "                break\n",
    "            \"\"\"\n",
    "            # Now update the previous frame and previous points\n",
    "            old_gray = frame_gray.copy()\n",
    "            p0 = good_new.reshape(-1,1,2)\n",
    "        frames = []\n",
    "        history_all_clips.append(history_clip)\n",
    "\n",
    "print(\"total frames \",count)\n",
    "# release and destroy all windows\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"history length\",len(history_all_clips))\\nprint(\"label objects length\",len(label_objects_array))\\nprint(\"length of active super pixels array\",len(active_super_pixels_array))\\nfor i in range(len(active_super_pixels_array)):\\n    print(\"no of active superpixels in clip \",i,\"is\",np.count_nonzero(active_super_pixels_array[i]))\\n    '"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "print(\"history length\",len(history_all_clips))\n",
    "print(\"label objects length\",len(label_objects_array))\n",
    "print(\"length of active super pixels array\",len(active_super_pixels_array))\n",
    "for i in range(len(active_super_pixels_array)):\n",
    "    print(\"no of active superpixels in clip \",i,\"is\",np.count_nonzero(active_super_pixels_array[i]))\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_formation(image):\n",
    "    shape = image.shape\n",
    "    x_val = shape[0]//3\n",
    "    y_val = shape[1]//3\n",
    "    regions_arr = image.reshape(int(shape[0]/x_val), x_val, -1, y_val).swapaxes(1,2).reshape(-1, x_val, y_val)\n",
    "    return regions_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def small_length(val,arr):\n",
    "    small_index = 0\n",
    "    small_count = math.inf\n",
    "    for i in range(len(arr)):\n",
    "        if val in arr[i]:\n",
    "            if small_count > len(arr[i]):\n",
    "                small_count = len(arr[i])\n",
    "                small_index = i\n",
    "    return small_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def in_list(c, region_list):\n",
    "    for i in range(len(region_list)):\n",
    "        if c in region_list[i]:\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def region_and_superpixels(segments):\n",
    "    #dividing the entire frame into regions assigning each pixel location to region number\n",
    "    #output: regions_ar- contains the information of superpixels belongs to that region\n",
    "    #        region_segments - for a particular pixel location its associated region number.\n",
    "    regions = region_formation(segments)\n",
    "    region_index = defaultdict(set)\n",
    "    x,m,n = regions.shape\n",
    "    for i in range(x):\n",
    "        for j in range(m):\n",
    "            for k in range(n):\n",
    "                region_index[i].add(regions[i][j][k])\n",
    "    regions_ar = defaultdict(list)\n",
    "    for i in range(len(region_index)):\n",
    "        regions_ar[i]=list(region_index[i])\n",
    "    for i in range(len(regions_ar)):\n",
    "        for j in range(len(regions_ar[i])):\n",
    "            region_num = small_length(regions_ar[i][j],regions)\n",
    "            for ind in range(len(regions_ar)):\n",
    "                if ind!=region_num and ind!=i:\n",
    "                    if regions_ar[i][j] in regions_ar[ind]:\n",
    "                        regions_ar[ind].remove(regions_ar[i][j])\n",
    "    # printing here region number and its particular superpixels. \n",
    "    #for i in range(len(regions_ar)):\n",
    "    #    print(\"region\",i,\" \",regions_ar[i])\n",
    "    region_segments = np.zeros_like(segments)\n",
    "    for i in range(len(segments)):\n",
    "        for j in range(len(segments[i])):\n",
    "            region_segments[i][j] = in_list(segments[i][j],regions_ar)\n",
    "    #for i in range(len(region_segments)):\n",
    "    #    print(region_segments[i])\n",
    "    return regions_ar,region_segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "region_segments_array = []\n",
    "for i in range(len(label_objects_array)):\n",
    "    regions_ar,region_segments = region_and_superpixels(label_objects_array[i].segments)\n",
    "    region_segments_array.append(region_segments)\n",
    "    #print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class bin_objects:\n",
    "    def __init__(self,superpixel,frame_no,bin_no,pixel_point,interest_point_no,region):\n",
    "        self.superpixel =superpixel\n",
    "        self.frame_no = frame_no\n",
    "        self.bin_no = bin_no\n",
    "        self.pixel_point = pixel_point\n",
    "        self.interest_point_no = interest_point_no\n",
    "        self.region = region"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 th clip no of interest points 147\n",
      "1 th clip no of interest points 144\n",
      "2 th clip no of interest points 135\n",
      "3 th clip no of interest points 148\n",
      "4 th clip no of interest points 152\n",
      "5 th clip no of interest points 152\n",
      "6 th clip no of interest points 151\n",
      "7 th clip no of interest points 159\n",
      "8 th clip no of interest points 161\n",
      "9 th clip no of interest points 158\n",
      "10 th clip no of interest points 163\n",
      "11 th clip no of interest points 151\n",
      "12 th clip no of interest points 157\n",
      "13 th clip no of interest points 162\n",
      "14 th clip no of interest points 166\n",
      "15 th clip no of interest points 150\n",
      "16 th clip no of interest points 155\n",
      "17 th clip no of interest points 161\n",
      "18 th clip no of interest points 135\n",
      "19 th clip no of interest points 164\n",
      "20 th clip no of interest points 156\n",
      "21 th clip no of interest points 163\n",
      "22 th clip no of interest points 167\n",
      "23 th clip no of interest points 146\n",
      "24 th clip no of interest points 171\n",
      "25 th clip no of interest points 165\n",
      "26 th clip no of interest points 164\n",
      "27 th clip no of interest points 166\n",
      "28 th clip no of interest points 164\n",
      "29 th clip no of interest points 168\n",
      "30 th clip no of interest points 148\n",
      "31 th clip no of interest points 167\n",
      "32 th clip no of interest points 166\n",
      "33 th clip no of interest points 153\n",
      "34 th clip no of interest points 187\n",
      "35 th clip no of interest points 165\n",
      "36 th clip no of interest points 171\n",
      "37 th clip no of interest points 184\n",
      "38 th clip no of interest points 182\n",
      "39 th clip no of interest points 174\n",
      "40 th clip no of interest points 170\n",
      "41 th clip no of interest points 158\n",
      "42 th clip no of interest points 187\n",
      "43 th clip no of interest points 162\n",
      "44 th clip no of interest points 175\n",
      "45 th clip no of interest points 179\n",
      "46 th clip no of interest points 177\n",
      "47 th clip no of interest points 176\n",
      "48 th clip no of interest points 161\n",
      "49 th clip no of interest points 161\n",
      "50 th clip no of interest points 184\n",
      "51 th clip no of interest points 188\n",
      "52 th clip no of interest points 182\n",
      "53 th clip no of interest points 183\n",
      "54 th clip no of interest points 157\n",
      "55 th clip no of interest points 176\n",
      "56 th clip no of interest points 160\n",
      "57 th clip no of interest points 154\n",
      "58 th clip no of interest points 158\n",
      "59 th clip no of interest points 162\n",
      "60 th clip no of interest points 154\n",
      "61 th clip no of interest points 168\n",
      "62 th clip no of interest points 162\n",
      "63 th clip no of interest points 151\n",
      "64 th clip no of interest points 145\n",
      "65 th clip no of interest points 160\n",
      "66 th clip no of interest points 154\n",
      "67 th clip no of interest points 156\n",
      "68 th clip no of interest points 166\n",
      "69 th clip no of interest points 164\n",
      "70 th clip no of interest points 161\n",
      "71 th clip no of interest points 169\n",
      "72 th clip no of interest points 160\n",
      "73 th clip no of interest points 172\n",
      "74 th clip no of interest points 166\n",
      "75 th clip no of interest points 159\n",
      "76 th clip no of interest points 166\n",
      "77 th clip no of interest points 174\n",
      "78 th clip no of interest points 162\n",
      "79 th clip no of interest points 168\n",
      "80 th clip no of interest points 160\n",
      "81 th clip no of interest points 172\n",
      "82 th clip no of interest points 177\n",
      "83 th clip no of interest points 168\n",
      "84 th clip no of interest points 140\n",
      "85 th clip no of interest points 168\n",
      "86 th clip no of interest points 152\n",
      "87 th clip no of interest points 149\n",
      "88 th clip no of interest points 156\n",
      "89 th clip no of interest points 159\n",
      "90 th clip no of interest points 160\n",
      "91 th clip no of interest points 174\n",
      "92 th clip no of interest points 181\n",
      "93 th clip no of interest points 171\n",
      "94 th clip no of interest points 161\n",
      "95 th clip no of interest points 167\n",
      "96 th clip no of interest points 151\n",
      "97 th clip no of interest points 157\n",
      "98 th clip no of interest points 192\n",
      "99 th clip no of interest points 162\n",
      "100 th clip no of interest points 161\n",
      "101 th clip no of interest points 157\n",
      "102 th clip no of interest points 165\n",
      "103 th clip no of interest points 163\n",
      "104 th clip no of interest points 175\n",
      "105 th clip no of interest points 176\n",
      "106 th clip no of interest points 161\n",
      "107 th clip no of interest points 161\n",
      "108 th clip no of interest points 168\n",
      "109 th clip no of interest points 153\n",
      "110 th clip no of interest points 179\n",
      "111 th clip no of interest points 171\n",
      "112 th clip no of interest points 183\n",
      "113 th clip no of interest points 167\n",
      "114 th clip no of interest points 145\n",
      "115 th clip no of interest points 160\n",
      "116 th clip no of interest points 166\n",
      "117 th clip no of interest points 167\n",
      "118 th clip no of interest points 138\n",
      "119 th clip no of interest points 158\n",
      "120 th clip no of interest points 134\n",
      "121 th clip no of interest points 123\n",
      "122 th clip no of interest points 130\n",
      "123 th clip no of interest points 141\n",
      "124 th clip no of interest points 146\n",
      "125 th clip no of interest points 147\n",
      "126 th clip no of interest points 160\n",
      "127 th clip no of interest points 165\n",
      "128 th clip no of interest points 157\n",
      "129 th clip no of interest points 143\n",
      "130 th clip no of interest points 150\n",
      "131 th clip no of interest points 160\n",
      "132 th clip no of interest points 151\n",
      "133 th clip no of interest points 171\n",
      "134 th clip no of interest points 142\n",
      "135 th clip no of interest points 173\n",
      "136 th clip no of interest points 152\n",
      "137 th clip no of interest points 187\n",
      "138 th clip no of interest points 138\n",
      "139 th clip no of interest points 172\n",
      "140 th clip no of interest points 139\n",
      "141 th clip no of interest points 151\n",
      "142 th clip no of interest points 157\n",
      "143 th clip no of interest points 160\n",
      "144 th clip no of interest points 156\n",
      "145 th clip no of interest points 152\n",
      "146 th clip no of interest points 159\n",
      "147 th clip no of interest points 160\n",
      "148 th clip no of interest points 156\n",
      "149 th clip no of interest points 167\n",
      "150 th clip no of interest points 173\n",
      "151 th clip no of interest points 152\n",
      "152 th clip no of interest points 158\n",
      "153 th clip no of interest points 157\n",
      "154 th clip no of interest points 146\n",
      "155 th clip no of interest points 131\n",
      "156 th clip no of interest points 123\n"
     ]
    }
   ],
   "source": [
    "codebook_all_clips = []\n",
    "bin_objects_array = []\n",
    "for i in range(len(history_all_clips)):\n",
    "    print(i,\"th clip no of interest points\",len(history_all_clips[i]))\n",
    "    codebook_region = defaultdict(list)\n",
    "    bin_objects_list = defaultdict(list)\n",
    "    for j in range(len(history_all_clips[i])):\n",
    "        history = np.asarray(history_all_clips[i][j])\n",
    "        bins = [-1]*len(history)\n",
    "        #superpixel value \n",
    "        suppix = label_objects_array[i].segments[int(history[0][1])][int(history[0][0])]\n",
    "        region = region_segments_array[i][int(history[0][1])][int(history[0][0])]\n",
    "        for k in range(len(history)-1):\n",
    "            if (history[k][0]==history[k+1][0]) and (history[k][1]==history[k+1][1]):\n",
    "                bins[k]=0\n",
    "            elif bins[k]!=0:\n",
    "                bins[k] = int((history[k][0]*history[k][1]+k)%8)+1\n",
    "            bin_objects_list[j].append(bin_objects(superpixel= suppix,frame_no = k+1,bin_no = bins[k],pixel_point=(history[k][0],history[k][1]),interest_point_no=j,region=region.copy()))\n",
    "        bins[len(history)-1] = 0\n",
    "        bin_objects_list[j].append(bin_objects(superpixel= suppix,frame_no = len(history),bin_no = bins[len(history)-1],pixel_point=(history[len(history)-1][0],history[len(history)-1][1]),interest_point_no=j,region=region.copy()))\n",
    "        #print(\"code word \",bins)\n",
    "        if active_super_pixels_array[i][suppix]==True:\n",
    "            codebook_region[region].append(bins)\n",
    "    codebook_all_clips.append(codebook_region)\n",
    "    bin_objects_array.append(bin_objects_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "from scipy.special import gammaln\n",
    "\n",
    "class DefaultDict(dict):\n",
    "    def __init__(self, v):\n",
    "        self.v = v\n",
    "        dict.__init__(self)\n",
    "    def __getitem__(self, k):\n",
    "        return dict.__getitem__(self, k) if k in self else self.v\n",
    "    def update(self, d):\n",
    "        dict.update(self, d)\n",
    "        return self\n",
    "\n",
    "class HDPLDA:\n",
    "    def __init__(self, alpha, beta, gamma, docs, V):\n",
    "        self.alpha = alpha\n",
    "        self.beta = beta\n",
    "        self.gamma = gamma\n",
    "        self.V = V\n",
    "        self.M = len(docs)\n",
    "\n",
    "        # t : table index for document j\n",
    "        #     t=0 means to draw a new table\n",
    "        self.using_t = [[0] for j in range(self.M)]\n",
    "\n",
    "        # k : dish(topic) index\n",
    "        #     k=0 means to draw a new dish\n",
    "        self.using_k = [0]\n",
    "\n",
    "        self.x_ji = docs # vocabulary for each document and term\n",
    "        self.k_jt = [numpy.zeros(1 ,dtype=int) for j in range(self.M)]   # topics of document and table\n",
    "        self.n_jt = [numpy.zeros(1 ,dtype=int) for j in range(self.M)]   # number of terms for each table of document\n",
    "        self.n_jtv = [[None] for j in range(self.M)]\n",
    "\n",
    "        self.m = 0\n",
    "        self.m_k = numpy.ones(1 ,dtype=int)  # number of tables for each topic\n",
    "        self.n_k = numpy.array([self.beta * self.V]) # number of terms for each topic ( + beta * V )\n",
    "        self.n_kv = [DefaultDict(0)]            # number of terms for each topic and vocabulary ( + beta )\n",
    "\n",
    "        # table for each document and term (-1 means not-assigned)\n",
    "        self.t_ji = [numpy.zeros(len(x_i), dtype=int) - 1 for x_i in docs]\n",
    "                    \n",
    "\n",
    "    def worddist(self):\n",
    "        \"\"\"return topic-word distribution without new topic\"\"\"\n",
    "        return [DefaultDict(self.beta / self.n_k[k]).update(\n",
    "            (v, n_kv / self.n_k[k]) for v, n_kv in self.n_kv[k].items())\n",
    "                for k in self.using_k if k != 0]\n",
    "\n",
    "    def docdist(self):\n",
    "        \"\"\"return document-topic distribution with new topic\"\"\"\n",
    "\n",
    "        # am_k = effect from table-dish assignment\n",
    "        am_k = numpy.array(self.m_k, dtype=float)\n",
    "        am_k[0] = self.gamma\n",
    "        am_k *= self.alpha / am_k[self.using_k].sum()\n",
    "\n",
    "        theta = []\n",
    "        for j, n_jt in enumerate(self.n_jt):\n",
    "            p_jk = am_k.copy()\n",
    "            for t in self.using_t[j]:\n",
    "                if t == 0: continue\n",
    "                k = self.k_jt[j][t]\n",
    "                p_jk[k] += n_jt[t]\n",
    "            p_jk = p_jk[self.using_k]\n",
    "            theta.append(p_jk / p_jk.sum())\n",
    "\n",
    "        return numpy.array(theta)\n",
    "    \n",
    "    def dump(self, disp_x=False):\n",
    "        if disp_x: print(\"x_ji:\", self.x_ji)\n",
    "        print(\"using_t:\", self.using_t)\n",
    "        print(\"t_ji:\", self.t_ji)\n",
    "        print(\"using_k:\", self.using_k)\n",
    "        print(\"k_jt:\", self.k_jt)\n",
    "        print(\"----\")\n",
    "        print(\"n_jt:\", self.n_jt)\n",
    "        print(\"n_jtv:\", self.n_jtv)\n",
    "        print(\"n_k:\", self.n_k)\n",
    "        print(\"n_kv:\", self.n_kv)\n",
    "        print(\"m:\", self.m)\n",
    "        print(\"m_k:\", self.m_k)\n",
    "\n",
    "\n",
    "    def sampling_t(self, j, i):\n",
    "        \"\"\"sampling t (table) from posterior\"\"\"\n",
    "        self.leave_from_table(j, i)\n",
    "\n",
    "        v = self.x_ji[j][i]\n",
    "        f_k = self.calc_f_k(v)\n",
    "        assert f_k[0] == 0 # f_k[0] is a dummy and will be erased\n",
    "\n",
    "        # sampling from posterior p(t_ji=t)\n",
    "        p_t = self.calc_table_posterior(j, f_k)\n",
    "        if len(p_t) > 1 and p_t[1] < 0: self.dump()\n",
    "        t_new = self.using_t[j][numpy.random.multinomial(1, p_t).argmax()]\n",
    "        if t_new == 0:\n",
    "            p_k = self.calc_dish_posterior_w(f_k)\n",
    "            k_new = self.using_k[numpy.random.multinomial(1, p_k).argmax()]\n",
    "            if k_new == 0:\n",
    "                k_new = self.add_new_dish()\n",
    "            t_new = self.add_new_table(j, k_new)\n",
    "\n",
    "        # increase counters\n",
    "        self.seat_at_table(j, i, t_new)\n",
    "        return p_t\n",
    "\n",
    "    def leave_from_table(self, j, i):\n",
    "        t = self.t_ji[j][i]\n",
    "        if t  > 0:\n",
    "            k = self.k_jt[j][t]\n",
    "            assert k > 0\n",
    "\n",
    "            # decrease counters\n",
    "            v = self.x_ji[j][i]\n",
    "            self.n_kv[k][v] -= 1\n",
    "            self.n_k[k] -= 1\n",
    "            self.n_jt[j][t] -= 1\n",
    "            self.n_jtv[j][t][v] -= 1\n",
    "\n",
    "            if self.n_jt[j][t] == 0:\n",
    "                self.remove_table(j, t)\n",
    "\n",
    "    def remove_table(self, j, t):\n",
    "        \"\"\"remove the table where all guests are gone\"\"\"\n",
    "        k = self.k_jt[j][t]\n",
    "        self.using_t[j].remove(t)\n",
    "        self.m_k[k] -= 1\n",
    "        self.m -= 1\n",
    "        assert self.m_k[k] >= 0\n",
    "        if self.m_k[k] == 0:\n",
    "            # remove topic (dish) where all tables are gone\n",
    "            self.using_k.remove(k)\n",
    "\n",
    "    def calc_f_k(self, v):\n",
    "        return [n_kv[v] for n_kv in self.n_kv] / self.n_k\n",
    "\n",
    "    def calc_table_posterior(self, j, f_k):\n",
    "        using_t = self.using_t[j]\n",
    "        p_t = self.n_jt[j][using_t] * f_k[self.k_jt[j][using_t]]\n",
    "        p_x_ji = numpy.inner(self.m_k, f_k) + self.gamma / self.V\n",
    "        p_t[0] = p_x_ji * self.alpha / (self.gamma + self.m)\n",
    "        #print(\"un-normalized p_t = \", p_t)\n",
    "        return p_t / p_t.sum()\n",
    "\n",
    "    def seat_at_table(self, j, i, t_new):\n",
    "        assert t_new in self.using_t[j]\n",
    "        self.t_ji[j][i] = t_new\n",
    "        self.n_jt[j][t_new] += 1\n",
    "\n",
    "        k_new = self.k_jt[j][t_new]\n",
    "        self.n_k[k_new] += 1\n",
    "\n",
    "        v = self.x_ji[j][i]\n",
    "        self.n_kv[k_new][v] += 1\n",
    "        self.n_jtv[j][t_new][v] += 1\n",
    "\n",
    "    # Assign guest x_ji to a new table and draw topic (dish) of the table\n",
    "    def add_new_table(self, j, k_new):\n",
    "        assert k_new in self.using_k\n",
    "        for t_new, t in enumerate(self.using_t[j]):\n",
    "            if t_new != t: break\n",
    "        else:\n",
    "            t_new = len(self.using_t[j])\n",
    "            self.n_jt[j].resize(t_new+1)\n",
    "            self.k_jt[j].resize(t_new+1)\n",
    "            self.n_jtv[j].append(None)\n",
    "\n",
    "        self.using_t[j].insert(t_new, t_new)\n",
    "        self.n_jt[j][t_new] = 0  # to make sure\n",
    "        self.n_jtv[j][t_new] = DefaultDict(0)\n",
    "\n",
    "        self.k_jt[j][t_new] = k_new\n",
    "        self.m_k[k_new] += 1\n",
    "        self.m += 1\n",
    "\n",
    "        return t_new\n",
    "\n",
    "    def calc_dish_posterior_w(self, f_k):\n",
    "        \"calculate dish(topic) posterior when one word is removed\"\n",
    "        p_k = (self.m_k * f_k)[self.using_k]\n",
    "        p_k[0] = self.gamma / self.V\n",
    "        return p_k / p_k.sum()\n",
    "\n",
    "\n",
    "\n",
    "    def sampling_k(self, j, t):\n",
    "        \"\"\"sampling k (dish=topic) from posterior\"\"\"\n",
    "        self.leave_from_dish(j, t)\n",
    "\n",
    "        # sampling of k\n",
    "        p_k = self.calc_dish_posterior_t(j, t)\n",
    "        k_new = self.using_k[numpy.random.multinomial(1, p_k).argmax()]\n",
    "        if k_new == 0:\n",
    "            k_new = self.add_new_dish()\n",
    "\n",
    "        self.seat_at_dish(j, t, k_new)\n",
    "\n",
    "    def leave_from_dish(self, j, t):\n",
    "        \"\"\"\n",
    "        This makes the table leave from its dish and only the table counter decrease.\n",
    "        The word counters (n_k and n_kv) stay.\n",
    "        \"\"\"\n",
    "        k = self.k_jt[j][t]\n",
    "        assert k > 0\n",
    "        assert self.m_k[k] > 0\n",
    "        self.m_k[k] -= 1\n",
    "        self.m -= 1\n",
    "        if self.m_k[k] == 0:\n",
    "            self.using_k.remove(k)\n",
    "            self.k_jt[j][t] = 0\n",
    "\n",
    "    def calc_dish_posterior_t(self, j, t):\n",
    "        \"calculate dish(topic) posterior when one table is removed\"\n",
    "        k_old = self.k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "        #print(\"V=\", self.V, \"beta=\", self.beta, \"n_k=\", self.n_k)\n",
    "        Vbeta = self.V * self.beta\n",
    "        n_k = self.n_k.copy()\n",
    "        n_jt = self.n_jt[j][t]\n",
    "        n_k[k_old] -= n_jt\n",
    "        n_k = n_k[self.using_k]\n",
    "        log_p_k = numpy.log(self.m_k[self.using_k]) + gammaln(n_k) - gammaln(n_k + n_jt)\n",
    "        log_p_k_new = numpy.log(self.gamma) + gammaln(Vbeta) - gammaln(Vbeta + n_jt)\n",
    "        #print(\"log_p_k_new+=gammaln(\",Vbeta,\") - gammaln(\",Vbeta + n_jt,\")\")\n",
    "\n",
    "        gammaln_beta = gammaln(self.beta)\n",
    "        for w, n_jtw in self.n_jtv[j][t].items():\n",
    "            assert n_jtw >= 0\n",
    "            if n_jtw == 0: continue\n",
    "            n_kw = numpy.array([n.get(w, self.beta) for n in self.n_kv])\n",
    "            n_kw[k_old] -= n_jtw\n",
    "            n_kw = n_kw[self.using_k]\n",
    "            n_kw[0] = 1 # dummy for logarithm's warning\n",
    "            if numpy.any(n_kw <= 0): print(n_kw) # for debug\n",
    "            log_p_k += gammaln(n_kw + n_jtw) - gammaln(n_kw)\n",
    "            log_p_k_new += gammaln(self.beta + n_jtw) - gammaln_beta\n",
    "            #print(\"log_p_k_new+=gammaln(\",self.beta + n_jtw,\") - gammaln(\",self.beta,\"), w=\",w)\n",
    "        log_p_k[0] = log_p_k_new\n",
    "        #print(\"un-normalized p_k = \", numpy.exp(log_p_k))\n",
    "        p_k = numpy.exp(log_p_k - log_p_k.max())\n",
    "        return p_k / p_k.sum()\n",
    "\n",
    "    def seat_at_dish(self, j, t, k_new):\n",
    "        self.m += 1\n",
    "        self.m_k[k_new] += 1\n",
    "\n",
    "        k_old = self.k_jt[j][t]     # it may be zero (means a removed dish)\n",
    "        if k_new != k_old:\n",
    "            self.k_jt[j][t] = k_new\n",
    "\n",
    "            n_jt = self.n_jt[j][t]\n",
    "            if k_old != 0: self.n_k[k_old] -= n_jt\n",
    "            self.n_k[k_new] += n_jt\n",
    "            for v, n in self.n_jtv[j][t].items():\n",
    "                if k_old != 0: self.n_kv[k_old][v] -= n\n",
    "                self.n_kv[k_new][v] += n\n",
    "\n",
    "\n",
    "    def add_new_dish(self):\n",
    "        \"This is commonly used by sampling_t and sampling_k.\"\n",
    "        for k_new, k in enumerate(self.using_k):\n",
    "            if k_new != k: break\n",
    "        else:\n",
    "            k_new = len(self.using_k)\n",
    "            if k_new >= len(self.n_kv):\n",
    "                self.n_k = numpy.resize(self.n_k, k_new + 1)\n",
    "                self.m_k = numpy.resize(self.m_k, k_new + 1)\n",
    "                self.n_kv.append(None)\n",
    "            assert k_new == self.using_k[-1] + 1\n",
    "            assert k_new < len(self.n_kv)\n",
    "\n",
    "        self.using_k.insert(k_new, k_new)\n",
    "        self.n_k[k_new] = self.beta * self.V\n",
    "        self.m_k[k_new] = 0\n",
    "        self.n_kv[k_new] = DefaultDict(self.beta)\n",
    "        return k_new\n",
    "    \n",
    "    def inference(self):\n",
    "        weights = []\n",
    "        for j, x_i in enumerate(self.x_ji):\n",
    "            p_t = []\n",
    "            for i in range(len(x_i)):\n",
    "                p_t = self.sampling_t(j, i)\n",
    "            weights.extend(p_t)\n",
    "        for j in range(self.M):\n",
    "            for t in self.using_t[j]:\n",
    "                if t != 0: self.sampling_k(j, t)\n",
    "        return np.asarray(weights).flatten()\n",
    "    \n",
    "    def hdplda_learning(self,iteration):\n",
    "        for i in range(iteration):\n",
    "            weights = self.inference()\n",
    "        return weights       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "class data_objects:\n",
    "    def __init__(self,clip_no,stime,etime,weights_data,label):\n",
    "        self.clip_no = clip_no\n",
    "        self.stime = stime\n",
    "        self.etime = etime\n",
    "        self.weights_data = weights_data\n",
    "        self.label = label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "clip no  0\n",
      "weights 732\n",
      "clip no  1\n",
      "weights 740\n",
      "clip no  2\n",
      "weights 704\n",
      "clip no  3\n",
      "weights 760\n",
      "clip no  4\n",
      "weights 779\n",
      "clip no  5\n",
      "weights 742\n",
      "clip no  6\n",
      "weights 750\n",
      "clip no  7\n",
      "weights 810\n",
      "clip no  8\n",
      "weights 831\n",
      "clip no  9\n",
      "weights 795\n",
      "clip no  10\n",
      "weights 771\n",
      "clip no  11\n",
      "weights 757\n",
      "clip no  12\n",
      "weights 831\n",
      "clip no  13\n",
      "weights 829\n",
      "clip no  14\n",
      "weights 885\n",
      "clip no  15\n",
      "weights 777\n",
      "clip no  16\n",
      "weights 736\n",
      "clip no  17\n",
      "weights 836\n",
      "clip no  18\n",
      "weights 713\n",
      "clip no  19\n",
      "weights 846\n",
      "clip no  20\n",
      "weights 828\n",
      "clip no  21\n",
      "weights 846\n",
      "clip no  22\n",
      "weights 834\n",
      "clip no  23\n",
      "weights 716\n",
      "clip no  24\n",
      "weights 851\n",
      "clip no  25\n",
      "weights 832\n",
      "clip no  26\n",
      "weights 857\n",
      "clip no  27\n",
      "weights 832\n",
      "clip no  28\n",
      "weights 817\n",
      "clip no  29\n",
      "weights 894\n",
      "clip no  30\n",
      "weights 748\n",
      "clip no  31\n",
      "weights 836\n",
      "clip no  32\n",
      "weights 845\n",
      "clip no  33\n",
      "weights 786\n",
      "clip no  34\n",
      "weights 965\n",
      "clip no  35\n",
      "weights 836\n",
      "clip no  36\n",
      "weights 884\n",
      "clip no  37\n",
      "weights 909\n",
      "clip no  38\n",
      "weights 924\n",
      "clip no  39\n",
      "weights 876\n",
      "clip no  40\n",
      "weights 855\n",
      "clip no  41\n",
      "weights 808\n",
      "clip no  42\n",
      "weights 996\n",
      "clip no  43\n",
      "weights 851\n",
      "clip no  44\n",
      "weights 877\n",
      "clip no  45\n",
      "weights 928\n",
      "clip no  46\n",
      "weights 925\n",
      "clip no  47\n",
      "weights 899\n",
      "clip no  48\n",
      "weights 835\n",
      "clip no  49\n",
      "weights 800\n",
      "clip no  50\n",
      "weights 967\n",
      "clip no  51\n",
      "weights 917\n",
      "clip no  52\n",
      "weights 903\n",
      "clip no  53\n",
      "weights 869\n",
      "clip no  54\n",
      "weights 842\n",
      "clip no  55\n",
      "weights 897\n",
      "clip no  56\n",
      "weights 797\n",
      "clip no  57\n",
      "weights 789\n",
      "clip no  58\n",
      "weights 835\n",
      "clip no  59\n",
      "weights 855\n",
      "clip no  60\n",
      "weights 766\n",
      "clip no  61\n",
      "weights 843\n",
      "clip no  62\n",
      "weights 808\n",
      "clip no  63\n",
      "weights 740\n",
      "clip no  64\n",
      "weights 741\n",
      "clip no  65\n",
      "weights 810\n",
      "clip no  66\n",
      "weights 805\n",
      "clip no  67\n",
      "weights 797\n",
      "clip no  68\n",
      "weights 852\n",
      "clip no  69\n",
      "weights 877\n",
      "clip no  70\n",
      "weights 802\n",
      "clip no  71\n",
      "weights 862\n",
      "clip no  72\n",
      "weights 791\n",
      "clip no  73\n",
      "weights 855\n",
      "clip no  74\n",
      "weights 814\n",
      "clip no  75\n",
      "weights 794\n",
      "clip no  76\n",
      "weights 836\n",
      "clip no  77\n",
      "weights 858\n",
      "clip no  78\n",
      "weights 847\n",
      "clip no  79\n",
      "weights 852\n",
      "clip no  80\n",
      "weights 795\n",
      "clip no  81\n",
      "weights 878\n",
      "clip no  82\n",
      "weights 874\n",
      "clip no  83\n",
      "weights 849\n",
      "clip no  84\n",
      "weights 732\n",
      "clip no  85\n",
      "weights 841\n",
      "clip no  86\n",
      "weights 736\n",
      "clip no  87\n",
      "weights 810\n",
      "clip no  88\n",
      "weights 849\n",
      "clip no  89\n",
      "weights 821\n",
      "clip no  90\n",
      "weights 808\n",
      "clip no  91\n",
      "weights 876\n",
      "clip no  92\n",
      "weights 923\n",
      "clip no  93\n",
      "weights 875\n",
      "clip no  94\n",
      "weights 828\n",
      "clip no  95\n",
      "weights 889\n",
      "clip no  96\n",
      "weights 795\n",
      "clip no  97\n",
      "weights 753\n",
      "clip no  98\n",
      "weights 942\n",
      "clip no  99\n",
      "weights 773\n",
      "clip no  100\n",
      "weights 856\n",
      "clip no  101\n",
      "weights 829\n",
      "clip no  102\n",
      "weights 867\n",
      "clip no  103\n",
      "weights 870\n",
      "clip no  104\n",
      "weights 912\n",
      "clip no  105\n",
      "weights 875\n",
      "clip no  106\n",
      "weights 822\n",
      "clip no  107\n",
      "weights 829\n",
      "clip no  108\n",
      "weights 892\n",
      "clip no  109\n",
      "weights 806\n",
      "clip no  110\n",
      "weights 875\n",
      "clip no  111\n",
      "weights 809\n",
      "clip no  112\n",
      "weights 877\n",
      "clip no  113\n",
      "weights 901\n",
      "clip no  114\n",
      "weights 751\n",
      "clip no  115\n",
      "weights 810\n",
      "clip no  116\n",
      "weights 846\n",
      "clip no  117\n",
      "weights 840\n",
      "clip no  118\n",
      "weights 692\n",
      "clip no  119\n",
      "weights 800\n",
      "clip no  120\n",
      "weights 710\n",
      "clip no  121\n",
      "weights 588\n",
      "clip no  122\n",
      "weights 698\n",
      "clip no  123\n",
      "weights 682\n",
      "clip no  124\n",
      "weights 745\n",
      "clip no  125\n",
      "weights 757\n",
      "clip no  126\n",
      "weights 784\n",
      "clip no  127\n",
      "weights 851\n",
      "clip no  128\n",
      "weights 825\n",
      "clip no  129\n",
      "weights 682\n",
      "clip no  130\n",
      "weights 764\n",
      "clip no  131\n",
      "weights 829\n",
      "clip no  132\n",
      "weights 755\n",
      "clip no  133\n",
      "weights 919\n",
      "clip no  134\n",
      "weights 709\n",
      "clip no  135\n",
      "weights 897\n",
      "clip no  136\n",
      "weights 766\n",
      "clip no  137\n",
      "weights 948\n",
      "clip no  138\n",
      "weights 703\n",
      "clip no  139\n",
      "weights 856\n",
      "clip no  140\n",
      "weights 680\n",
      "clip no  141\n",
      "weights 728\n",
      "clip no  142\n",
      "weights 781\n",
      "clip no  143\n",
      "weights 864\n",
      "clip no  144\n",
      "weights 838\n",
      "clip no  145\n",
      "weights 739\n",
      "clip no  146\n",
      "weights 829\n",
      "clip no  147\n",
      "weights 797\n",
      "clip no  148\n",
      "weights 843\n",
      "clip no  149\n",
      "weights 870\n",
      "clip no  150\n",
      "weights 959\n",
      "clip no  151\n",
      "weights 803\n",
      "clip no  152\n",
      "weights 822\n",
      "clip no  153\n",
      "weights 822\n",
      "clip no  154\n",
      "weights 687\n",
      "clip no  155\n",
      "weights 635\n",
      "clip no  156\n",
      "weights 549\n"
     ]
    }
   ],
   "source": [
    "data_object_array=[]\n",
    "loa = label_objects_array\n",
    "for i in range(len(codebook_all_clips)):\n",
    "    print(\"clip no \",i)\n",
    "    clip_weights = []\n",
    "    for j in range(len(codebook_all_clips[i])):\n",
    "        #print(\"region no\",j)\n",
    "        if len(codebook_all_clips[i][j])!=0:\n",
    "            hdplda = HDPLDA(1,1,1, codebook_all_clips[i][j],(12*12)+1)\n",
    "            weights = hdplda.hdplda_learning(3)\n",
    "            clip_weights.extend(weights)\n",
    "    data_object_array.append(data_objects(loa[i].clip_no,loa[i].stime,loa[i].etime,np.asarray(clip_weights).flatten(),loa[i].label)) \n",
    "    print(\"weights\",len(clip_weights))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nprint(\"total no of objects\",len(total_data_objects))\\nfor i in range(len(total_data_objects)):\\n    print(\"clip no=\",total_data_objects[i].clip_no)\\n    print(\"start time=\",total_data_objects[i].stime)\\n    print(\"end time=\",total_data_objects[i].etime)\\n    print(\"weights =\",total_data_objects[i].weights_data)\\n    print(\"label = \",total_data_objects[i].label,\"\\n\")\\n    '"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_data_objects = data_object_array\n",
    "\"\"\"\n",
    "print(\"total no of objects\",len(total_data_objects))\n",
    "for i in range(len(total_data_objects)):\n",
    "    print(\"clip no=\",total_data_objects[i].clip_no)\n",
    "    print(\"start time=\",total_data_objects[i].stime)\n",
    "    print(\"end time=\",total_data_objects[i].etime)\n",
    "    print(\"weights =\",total_data_objects[i].weights_data)\n",
    "    print(\"label = \",total_data_objects[i].label,\"\\n\")\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_roc_curve(fpr, tpr):\n",
    "    plt.plot(fpr, tpr, color='orange', label='ROC')\n",
    "    plt.plot([0, 1], [0, 1], color='darkblue', linestyle='--')\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('Receiver Operating Characteristic (ROC) Curve')\n",
    "    plt.legend()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# normalizing weights.\n",
    "for i in range(len(total_data_objects)):\n",
    "    sum = np.sum(total_data_objects[i].weights_data)\n",
    "    for j in range(len(total_data_objects[i].weights_data)):\n",
    "        total_data_objects[i].weights_data[j] = total_data_objects[i].weights_data[j] / sum\n",
    "    total_data_objects[i].weights_data = np.asarray(total_data_objects[i].weights_data)\n",
    "    #print(\"sum \",i,\"\",np.sum(total_data_objects[i].weights_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max len 996\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'\\nfor i in range(len(total_data_objects)):\\n    for j in range(len(total_data_objects[i].weights_data)-min_len):\\n        total_data_objects[i].weights_data = np.delete(total_data_objects[i].weights_data,j)\\n\\nprint(\"after preprocessing lengths\")\\nfor i in range(len(total_data_objects)):\\n    print(len(total_data_objects[i].weights_data))\\n'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len = len(total_data_objects[0].weights_data)\n",
    "for i in range(len(total_data_objects)):\n",
    "    if max_len < len(total_data_objects[i].weights_data):\n",
    "        max_len = len(total_data_objects[i].weights_data)\n",
    "print(\"max len\",max_len)\n",
    "\n",
    "\"\"\"\n",
    "min_len = len(total_data_objects[0].weights_data)\n",
    "for i in range(len(total_data_objects)):\n",
    "    if min_len > len(total_data_objects[i].weights_data):\n",
    "        min_len = len(total_data_objects[i].weights_data)\n",
    "print(\"min len\",min_len)\n",
    "\"\"\"\n",
    "\n",
    "for i in range(len(total_data_objects)):\n",
    "    for j in range(max_len - len(total_data_objects[i].weights_data)):\n",
    "        total_data_objects[i].weights_data = np.append(total_data_objects[i].weights_data,0)\n",
    "\n",
    "for i in range(len(total_data_objects)):\n",
    "    #print(\"clip no\",i)\n",
    "    for j in range(len(total_data_objects[i].weights_data)):\n",
    "        if total_data_objects[i].weights_data[j] == 0:\n",
    "            total_data_objects[i].weights_data[j] = np.mean([total_data_objects[ind].weights_data[j] for ind in range(len(total_data_objects))])\n",
    "\"\"\"\n",
    "for i in range(len(total_data_objects)):\n",
    "    for j in range(len(total_data_objects[i].weights_data)-min_len):\n",
    "        total_data_objects[i].weights_data = np.delete(total_data_objects[i].weights_data,j)\n",
    "\n",
    "print(\"after preprocessing lengths\")\n",
    "for i in range(len(total_data_objects)):\n",
    "    print(len(total_data_objects[i].weights_data))\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total objects= 157\n",
      "train objects= 94\n",
      "test objects= 63\n"
     ]
    }
   ],
   "source": [
    "#dividing the total dataset into 60% training and 40% test\n",
    "total_no = len(total_data_objects)\n",
    "print(\"total objects=\",total_no)\n",
    "train_no=round(0.6*total_no)\n",
    "print(\"train objects=\",train_no)\n",
    "test_no=round(0.4*total_no)\n",
    "print(\"test objects=\",test_no)\n",
    "\n",
    "X_train=[]\n",
    "X_test=[]\n",
    "Y_train=[]\n",
    "Y_test=[]\n",
    "\n",
    "np.random.shuffle(total_data_objects)\n",
    "for i in range(train_no):\n",
    "    X_train.append(np.asarray(total_data_objects[i].weights_data))\n",
    "    Y_train.append(total_data_objects[i].label)\n",
    "for i in range(train_no,total_no):\n",
    "    X_test.append(total_data_objects[i].weights_data)\n",
    "    Y_test.append(total_data_objects[i].label)\n",
    "\n",
    "X_test=np.array(X_test)\n",
    "X_train=np.asarray(X_train)\n",
    "#print(\"X_test\",X_test)\n",
    "#print(\"x_trin shape\",X_train.shape)\n",
    "#print(\"X_train\",X_train[0].shape)    \n",
    "\n",
    "Y_test=np.asarray(Y_test)\n",
    "Y_train=np.asarray(Y_train)\n",
    "Y_test=Y_test\n",
    "Y_train=Y_train\n",
    "Y_test=Y_test.reshape(-1,1)\n",
    "Y_train=Y_train.reshape(-1,1)\n",
    "#print(len(Y_train))\n",
    "#print(Y_train[1:20,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shape  (94, 996)\n",
      "shape  (94, 1)\n",
      "labels predicted 63\n",
      "[[ 1 -1 -1 -1  1 -1 -1 -1  1  1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      "  -1 -1 -1  1 -1 -1 -1 -1 -1 -1  1 -1  1 -1  1 -1  1 -1 -1  1  1  1 -1 -1\n",
      "  -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1  1  1 -1 -1]]\n",
      "[-1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1\n",
      " -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1 -1]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:206: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "print(\"shape \",X_train.shape)\n",
    "print(\"shape \",Y_train.shape)\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train,Y_train)\n",
    "pred_labels=gnb.predict(X_test)\n",
    "print(\"labels predicted\",len(pred_labels))\n",
    "print(Y_test.reshape(1,-1))\n",
    "print(pred_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 77.77777777777779\n"
     ]
    }
   ],
   "source": [
    "#performance\n",
    "print(\"accuracy =\",accuracy_score(pred_labels,Y_test)*100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[49 14]\n",
      " [ 0  0]]\n"
     ]
    }
   ],
   "source": [
    "cm = confusion_matrix(pred_labels,Y_test)\n",
    "print(cm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AUC: 0.50\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "auc = roc_auc_score(Y_test,pred_labels)\n",
    "print('AUC: %.2f' % auc)\n",
    "fpr, tpr, thresholds = roc_curve(Y_test,pred_labels)\n",
    "plot_roc_curve(fpr, tpr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
